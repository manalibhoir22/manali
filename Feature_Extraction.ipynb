{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRvkEkj2XfhKYRXY5IY76x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manalibhoir22/manali/blob/master/Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36VxWrKtQ_Sf",
        "outputId": "33efe704-a623-4b91-f0d2-e8a01a2f0d4d"
      },
      "source": [
        "#countvecorizer with unigrams\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        " \n",
        "Doc1 = \"I do not like this product. Hate it\"\n",
        "Doc2 = \"This is an okay product works fine\"\n",
        "Doc3 = \"I do love this product\"\n",
        " \n",
        "stop_words = ['in','of','at','a','the','and','is','on','an','they','was','it','i','them','to','these','this']\n",
        "CountVec = CountVectorizer(stop_words=stop_words)\n",
        "#transform\n",
        "Count_data = CountVec.fit_transform([Doc1,Doc2,Doc3])\n",
        " \n",
        "#create dataframe\n",
        "cv_dataframe=pd.DataFrame(Count_data.toarray(),columns=CountVec.get_feature_names(),index=['Doc1', 'Doc2', 'Doc3'])\n",
        "print(cv_dataframe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      do  fine  hate  like  love  not  okay  product  works\n",
            "Doc1   1     0     1     1     0    1     0        1      0\n",
            "Doc2   0     1     0     0     0    0     1        1      1\n",
            "Doc3   1     0     0     0     1    0     0        1      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cMXxEcPWN4Z",
        "outputId": "8f9b1fb1-bc3a-4c34-c7ec-a5168b5f8cca"
      },
      "source": [
        "#printing vocab\n",
        "document = [\"I do not like this product. Hate it ,This is an okay product works fine,I do love this product\"]\n",
        "cv_doc = CountVectorizer(document,stop_words=stop_words)\n",
        "cv_vector = cv_doc.fit_transform(document)\n",
        "print(cv_doc.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'do': 0, 'not': 5, 'like': 3, 'product': 7, 'hate': 2, 'okay': 6, 'works': 8, 'fine': 1, 'love': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZT8oii1NzfS",
        "outputId": "2fd4b75a-0b36-4765-ba80-81c5a059d404"
      },
      "source": [
        "#countvecorizer bigrams\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        " \n",
        "Doc1 = \"I do not like this product. Hate it\"\n",
        "Doc2 = \"This is an okay product works fine\"\n",
        "Doc3 = \"I do love this product\"\n",
        " \n",
        "stop_words = ['in','of','at','a','the','and','is','on','an','they','was','it','i','them','to','these','this']\n",
        "CountVec = CountVectorizer(ngram_range=(1,2),\n",
        "                           stop_words=stop_words)\n",
        "#transform\n",
        "Count_data = CountVec.fit_transform([Doc1,Doc2,Doc3])\n",
        " \n",
        "#create dataframe\n",
        "cv_dataframe=pd.DataFrame(Count_data.toarray(),columns=CountVec.get_feature_names(),index=['Doc1', 'Doc2', 'Doc3'])\n",
        "print(cv_dataframe)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      do  do love  do not  fine  ...  product hate  product works  works  works fine\n",
            "Doc1   1        0       1     0  ...             1              0      0           0\n",
            "Doc2   0        0       0     1  ...             0              1      1           1\n",
            "Doc3   1        1       0     0  ...             0              0      0           0\n",
            "\n",
            "[3 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32H-0VYsC-BN"
      },
      "source": [
        "TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e59aEJGvN9IC",
        "outputId": "6c6e5b26-96a9-49ee-cf55-28b018be0446"
      },
      "source": [
        "#TFIDF \n",
        "Doc1 = \"I do not like this product. Hate it\"\n",
        "Doc2 = \"This is an okay product works fine\"\n",
        "Doc3 = \"I do love this product\"\n",
        "\n",
        "stop_words = ['in','of','at','a','the','and','is','on','an','they','was','it','i','them','to','these','this','for']\n",
        "\n",
        "#define tf-idf\n",
        "tf_idf_vec = TfidfVectorizer(ngram_range=(1,2),stop_words=stop_words) # to use only  bigrams ngram_range=(2,2)\n",
        "#transform\n",
        "tf_idf_data = tf_idf_vec.fit_transform([Doc1,Doc2,Doc3])\n",
        " \n",
        "#create dataframe\n",
        "tf_idf_dataframe=pd.DataFrame(tf_idf_data.toarray(),columns=tf_idf_vec.get_feature_names(),index=['Doc1', 'Doc2', 'Doc3'])\n",
        "print(tf_idf_dataframe)\n",
        "print(\"\\n\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            do   do love    do not  ...  product works     works  works fine\n",
            "Doc1  0.270118  0.000000  0.355173  ...       0.000000  0.000000    0.000000\n",
            "Doc2  0.000000  0.000000  0.000000  ...       0.396875  0.396875    0.396875\n",
            "Doc3  0.383770  0.504611  0.000000  ...       0.000000  0.000000    0.000000\n",
            "\n",
            "[3 rows x 18 columns]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJf6zy7FDere",
        "outputId": "2cf760ed-66a8-4d8f-db8a-a1a0c275197d"
      },
      "source": [
        "#TFIDF unigrams\n",
        "Doc1 = \"I do not like this product. Hate it\"\n",
        "Doc2 = \"This is an okay product works fine\"\n",
        "Doc3 = \"I do love this product\"\n",
        "\n",
        "stop_words = ['in','of','at','a','the','and','is','on','an','they','was','it','i','them','to','these','this','for']\n",
        "\n",
        "#define tf-idf\n",
        "tf_idf_vec = TfidfVectorizer(stop_words=stop_words) # to use only  bigrams ngram_range=(2,2)\n",
        "#transform\n",
        "tf_idf_data = tf_idf_vec.fit_transform([Doc1,Doc2,Doc3])\n",
        " \n",
        "#create dataframe\n",
        "tf_idf_dataframe=pd.DataFrame(tf_idf_data.toarray(),columns=tf_idf_vec.get_feature_names(),index=['Doc1', 'Doc2', 'Doc3'])\n",
        "print(tf_idf_dataframe)\n",
        "print(\"\\n\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            do      fine      hate  ...      okay   product     works\n",
            "Doc1  0.383770  0.000000  0.504611  ...  0.000000  0.298032  0.000000\n",
            "Doc2  0.000000  0.546454  0.000000  ...  0.546454  0.322745  0.546454\n",
            "Doc3  0.547832  0.000000  0.000000  ...  0.000000  0.425441  0.000000\n",
            "\n",
            "[3 rows x 9 columns]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbsySAipGyoh",
        "outputId": "89ead7a8-2cf7-4a83-cb6e-6f5c40b97079"
      },
      "source": [
        "##IDF\n",
        "# create the transform\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
        "# tokenize and build vocab\n",
        "vectorizer.fit([Doc1,Doc2,Doc3])\n",
        "# summarize\n",
        "print(vectorizer.vocabulary_)\n",
        "print(vectorizer.idf_)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'do': 0, 'not': 5, 'like': 3, 'product': 7, 'hate': 2, 'okay': 6, 'works': 8, 'fine': 1, 'love': 4}\n",
            "[1.28768207 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
            " 1.69314718 1.         1.69314718]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLdjfvlgggF6",
        "outputId": "6e636404-839b-45b5-b892-c63fb775374e"
      },
      "source": [
        "#TFIDF\n",
        "# encode document\n",
        "vector = vectorizer.transform([Doc1,Doc2,Doc3])\n",
        "# summarize encoded vector\n",
        "print(vector.shape)\n",
        "print(vector.toarray())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 9)\n",
            "[[0.38376993 0.         0.50461134 0.50461134 0.         0.50461134\n",
            "  0.         0.29803159 0.        ]\n",
            " [0.         0.54645401 0.         0.         0.         0.\n",
            "  0.54645401 0.32274454 0.54645401]\n",
            " [0.54783215 0.         0.         0.         0.72033345 0.\n",
            "  0.         0.42544054 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSAKdJZt3I2J"
      },
      "source": [
        "def tf(corpus):\n",
        "    tfs = []\n",
        "    for document in corpus:\n",
        "        dic={}\n",
        "        for word in document.split():\n",
        "            if word in dic:\n",
        "                dic[word]+=1\n",
        "            else:\n",
        "                dic[word]=1\n",
        "        for word,freq in dic.items():\n",
        "            #print(word,freq)\n",
        "            dic[word]=freq/len(document.split())\n",
        "        tfs.append(dic)\n",
        "    return tfs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2965d02L3kbE"
      },
      "source": [
        "l = ['do not like product. Hate' ,'okay product works fine','do love product']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzCc16J63qPK",
        "outputId": "841d29cd-3df0-4d77-b7c4-eb2b6d2ad892"
      },
      "source": [
        "tf(l) ##TF"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Hate': 0.2, 'do': 0.2, 'like': 0.2, 'not': 0.2, 'product.': 0.2},\n",
              " {'fine': 0.25, 'okay': 0.25, 'product': 0.25, 'works': 0.25},\n",
              " {'do': 0.3333333333333333,\n",
              "  'love': 0.3333333333333333,\n",
              "  'product': 0.3333333333333333}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5c80fPv3rSI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}